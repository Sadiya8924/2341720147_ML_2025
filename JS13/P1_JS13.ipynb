{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXPDX75+fkmg38YtLXmFMw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Praktikum 1"],"metadata":{"id":"O9c7G_lS8zpU"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNZ3HniJ67dy","outputId":"0c0ab2b0-bda6-4194-b2e8-3a88179c0bf4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.2655529933008129\n","Epoch 1000, Loss: 0.25019573226036784\n","Epoch 2000, Loss: 0.2497054225357766\n","Epoch 3000, Loss: 0.24809564163930045\n","Epoch 4000, Loss: 0.23006160440788337\n","Epoch 5000, Loss: 0.11644535237074954\n","Epoch 6000, Loss: 0.02488539238070605\n","Epoch 7000, Loss: 0.010854365876961675\n","Epoch 8000, Loss: 0.006581928305737093\n","Epoch 9000, Loss: 0.004631553379062043\n","Prediksi:\n","[[0.06016104]\n"," [0.94526047]\n"," [0.93102247]\n"," [0.05278357]]\n"]}],"source":["import numpy as np\n","\n","# Dataset XOR\n","X = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y = np.array([[0],[1],[1],[0]])\n","\n","# Parameter\n","input_size = 2\n","hidden_size = 2\n","output_size = 1\n","lr = 0.1\n","\n","# Inisialisasi bobot\n","W1 = np.random.randn(input_size, hidden_size)\n","b1 = np.zeros((1, hidden_size))\n","W2 = np.random.randn(hidden_size, output_size)\n","b2 = np.zeros((1, output_size))\n","\n","# Fungsi aktivasi\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","# Training\n","for epoch in range(10000):\n","    # Forward pass\n","    z1 = np.dot(X, W1) + b1\n","    a1 = sigmoid(z1)\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    # Hitung error\n","    error = y - a2\n","\n","    # Backpropagation\n","    d_a2 = error * sigmoid_derivative(a2)\n","    d_W2 = np.dot(a1.T, d_a2)\n","    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n","\n","    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n","    d_W1 = np.dot(X.T, d_a1)\n","    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n","\n","    # Update bobot\n","    W1 += lr * d_W1\n","    b1 += lr * d_b1\n","    W2 += lr * d_W2\n","    b2 += lr * d_b2\n","\n","    if epoch % 1000 == 0:\n","        loss = np.mean(np.square(error))\n","        print(f\"Epoch {epoch}, Loss: {loss}\")\n","\n","# Output akhir\n","print(\"Prediksi:\")\n","print(a2)"]},{"cell_type":"markdown","source":["#Tugas"],"metadata":{"id":"ez5zd4_19Nxg"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Dataset XOR\n","X = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y = np.array([[0],[1],[1],[0]])\n","\n","# --- PERUBAHAN DI SINI ---\n","input_size = 2\n","hidden_size = 3  # Mengubah jumlah neuron hidden layer menjadi 3\n","output_size = 1\n","lr = 0.1\n","# -------------------------\n","\n","np.random.seed(42) # Agar perbandingan fair\n","W1 = np.random.randn(input_size, hidden_size)\n","b1 = np.zeros((1, hidden_size))\n","W2 = np.random.randn(hidden_size, output_size)\n","b2 = np.zeros((1, output_size))\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","print(\"--- Training dengan 3 Hidden Neurons ---\")\n","for epoch in range(10000):\n","    # Forward pass\n","    z1 = np.dot(X, W1) + b1\n","    a1 = sigmoid(z1)\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    # Error\n","    error = y - a2\n","\n","    # Backprop\n","    d_a2 = error * sigmoid_derivative(a2)\n","    d_W2 = np.dot(a1.T, d_a2)\n","    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n","\n","    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n","    d_W1 = np.dot(X.T, d_a1)\n","    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n","\n","    # Update\n","    W1 += lr * d_W1\n","    b1 += lr * d_b1\n","    W2 += lr * d_W2\n","    b2 += lr * d_b2\n","\n","    if epoch % 1000 == 0:\n","        loss = np.mean(np.square(error))\n","        print(f\"Epoch {epoch}, Loss: {loss}\")\n","\n","print(\"Prediksi (3 Hidden Neurons):\")\n","print(a2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0991s9tP9EzZ","outputId":"78d09628-011d-4944-8cad-880d7b164cd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Training dengan 3 Hidden Neurons ---\n","Epoch 0, Loss: 0.31824520886068175\n","Epoch 1000, Loss: 0.20569699294249036\n","Epoch 2000, Loss: 0.1418539809567309\n","Epoch 3000, Loss: 0.058651326187686294\n","Epoch 4000, Loss: 0.020112046660991083\n","Epoch 5000, Loss: 0.009992200114726162\n","Epoch 6000, Loss: 0.006269504240552608\n","Epoch 7000, Loss: 0.004460666233485042\n","Epoch 8000, Loss: 0.003421033634262056\n","Epoch 9000, Loss: 0.0027556015957289\n","Prediksi (3 Hidden Neurons):\n","[[0.02515564]\n"," [0.95263635]\n"," [0.95122343]\n"," [0.0627247 ]]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","X = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y = np.array([[0],[1],[1],[0]])\n","\n","input_size = 2\n","hidden_size = 3 # Tetap menggunakan 3 neuron sesuai tugas sebelumnya\n","output_size = 1\n","lr = 0.1\n","\n","np.random.seed(42)\n","W1 = np.random.randn(input_size, hidden_size)\n","b1 = np.zeros((1, hidden_size))\n","W2 = np.random.randn(hidden_size, output_size)\n","b2 = np.zeros((1, output_size))\n","\n","# --- DEFINISI FUNGSI BARU ---\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","def relu(x):\n","    return np.maximum(0, x)\n","\n","def relu_derivative(x):\n","    # Turunan ReLU adalah 1 jika x > 0, dan 0 jika x <= 0\n","    return (x > 0).astype(float)\n","# -----------------------------\n","\n","print(\"\\n--- Training dengan ReLU (Hidden) & Sigmoid (Output) ---\")\n","for epoch in range(10000):\n","    # Forward pass\n","    z1 = np.dot(X, W1) + b1\n","    a1 = relu(z1)           # MENGGUNAKAN RELU DI HIDDEN LAYER\n","\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)        # TETAP SIGMOID DI OUTPUT\n","\n","    # Error\n","    error = y - a2\n","\n","    # Backpropagation\n","    d_a2 = error * sigmoid_derivative(a2)\n","    d_W2 = np.dot(a1.T, d_a2)\n","    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n","\n","    # Backprop ke Hidden Layer (Gunakan turunan ReLU)\n","    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(a1)\n","    d_W1 = np.dot(X.T, d_a1)\n","    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n","\n","    # Update\n","    W1 += lr * d_W1\n","    b1 += lr * d_b1\n","    W2 += lr * d_W2\n","    b2 += lr * d_b2\n","\n","    if epoch % 1000 == 0:\n","        loss = np.mean(np.square(error))\n","        print(f\"Epoch {epoch}, Loss: {loss}\")\n","\n","print(\"Prediksi (ReLU):\")\n","print(a2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5j9FwRE9FSp","outputId":"a4bdf444-7ebc-452d-8206-1e961d9a49c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Training dengan ReLU (Hidden) & Sigmoid (Output) ---\n","Epoch 0, Loss: 0.3274780407035275\n","Epoch 1000, Loss: 0.012797082733424602\n","Epoch 2000, Loss: 0.003283471866346602\n","Epoch 3000, Loss: 0.001730956726043575\n","Epoch 4000, Loss: 0.001146816158135167\n","Epoch 5000, Loss: 0.0008463615651895275\n","Epoch 6000, Loss: 0.0006661559173500909\n","Epoch 7000, Loss: 0.0005467478016979456\n","Epoch 8000, Loss: 0.00046239544032793036\n","Epoch 9000, Loss: 0.0003996816119159116\n","Prediksi (ReLU):\n","[[0.02970009]\n"," [0.98605912]\n"," [0.98605934]\n"," [0.01163533]]\n"]}]}]}